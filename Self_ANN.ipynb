{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset (MNIST Flattened CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = pd.read_csv(\"mnist.csv\")\n",
    "\n",
    "# Flattened MNIST Images.\n",
    "\n",
    "data = np.array(mnist)\n",
    "\n",
    "X = data[:,:-1]\n",
    "\n",
    "y = data[:,-1]\n",
    "y_oht = to_categorical(y,num_classes=10, dtype='int32')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_oht, test_size=0.2, random_state=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective:\n",
    "        \n",
    "        We need to classify the given flattened grayscale images into the 10 digits of Decimal system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(a):\n",
    "    ea = np.exp(a)\n",
    "    return ea/np.sum(ea,axis=1,keepdims=True)\n",
    "\n",
    "# Dimensionality needs to be maintained.\n",
    "\n",
    "\n",
    "class NeuralNetwork:\n",
    "    \n",
    "    # Constructing 3 layer acrchitecture with softmax as output activation.\n",
    "    \n",
    "    def __init__(self,input_size,h1,h2,output_size):    # h1 -> number of neurons in first layer\n",
    "                                                        # h2 -> number of neurons in second layer\n",
    "        model = {}\n",
    "        model[\"W1\"] = np.random.randn(input_size,h1)    # Weight Matrix for first layer\n",
    "        model[\"b1\"] = np.zeros((1,h1))                  # Bias for first layer\n",
    "\n",
    "        model[\"W2\"] = np.random.randn(h1,h2)              # Weight Matrix for second layer\n",
    "        model[\"b2\"] = np.zeros((1,h2))                    # Bias for second layer\n",
    "\n",
    "        model[\"W3\"] = np.random.randn(h2,output_size)     # Weight Matrix for third layer \n",
    "        model[\"b3\"] = np.zeros((1,output_size))           # Bias for third layer\n",
    "        \n",
    "        self.activation_outputs = (-1,-1,-1)            # Activation outputs after each layer\n",
    "\n",
    "        self.model = model\n",
    "\n",
    "        \n",
    "        \n",
    "#   Forward Propogation ...        \n",
    "        \n",
    "    def forward(self,X):\n",
    "        \n",
    "        model = self.model\n",
    "        W1,W2,W3 = model[\"W1\"],model[\"W2\"],model[\"W3\"]\n",
    "        b1,b2,b3 = model[\"b1\"],model[\"b2\"],model[\"b3\"]\n",
    "\n",
    "        # First Layer\n",
    "        z1 = np.dot(X,W1) + b1\n",
    "        a1 = np.tanh(z1)          # tanh activation\n",
    "\n",
    "        #Second Layer\n",
    "        z2 = np.dot(a1,W2) + b2\n",
    "        a2 = np.tanh(z2)          # tanh activation\n",
    "\n",
    "        #Third Layer\n",
    "        z3 = np.dot(a2,W3) + b3\n",
    "        a3 = softmax(z3)          # Softmax Activation\n",
    "\n",
    "\n",
    "        self.activation_outputs = (a1,a2,a3)\n",
    "        return a3                 # Final Output is from softmax activation\n",
    "    \n",
    "    \n",
    "    \n",
    "#   Back Propogation...\n",
    "    \n",
    "    def backward(self,X,y,learning_rate):\n",
    "\n",
    "        m = X.shape[0]\n",
    "        model = self.model\n",
    "        (a1,a2,a3) = self.activation_outputs \n",
    "        W1,W2,W3 = model[\"W1\"],model[\"W2\"],model[\"W3\"]\n",
    "        b1,b2,b3 = model[\"b1\"],model[\"b2\"],model[\"b3\"]\n",
    "        \n",
    "        # Delta3,dw3,db3\n",
    "        delta3 = a3 - y               # for cross entropy, softmax activation\n",
    "        dw3 = np.dot(a2.T,delta3)     # (h2Xm,mXc) = (h2Xc) = W3.shape\n",
    "        db3 = np.sum(delta3,axis=0)   \n",
    "\n",
    "        # Delta2, dw2, db2\n",
    "        delta2 = np.dot(delta3,W3.T)*(1-np.square(a2))\n",
    "        dw2 = np.dot(a1.T,delta2) # (h1Xm,mXh2) = (h1Xh2) = W2.shape\n",
    "        db2 = np.sum(delta2,axis=0)\n",
    "\n",
    "        # Delta1, dw1, db1\n",
    "        delta1 = np.dot(delta2,W2.T)*(1-np.square(a1))\n",
    "        dw1 = np.dot(X.T,delta1)\n",
    "        db1 = np.sum(delta1,axis=0)\n",
    "\n",
    "        #Gradient Descent\n",
    "        \n",
    "        self.model[\"W1\"] -= learning_rate*dw1\n",
    "        self.model[\"W2\"] -= learning_rate*dw2\n",
    "        self.model[\"W3\"] -= learning_rate*dw3\n",
    "\n",
    "        self.model[\"b1\"] -= learning_rate*db1\n",
    "        self.model[\"b2\"] -= learning_rate*db2\n",
    "        self.model[\"b3\"] -= learning_rate*db3\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    def predict(self,X):\n",
    "        \n",
    "        y_pred = self.forward(X)           # Prediction is just the forward pass for X_test\n",
    "        return np.argmax(y_pred,axis=1)    # Prediction for the output with max probability \n",
    "\n",
    "\n",
    "    def loss(self,y_oht,pred):              \n",
    "        return -1*np.mean(y_oht*np.log(pred))   # Implementing Cross-Entropy Loss\n",
    "    \n",
    "    \n",
    "    \n",
    "    def train(self,X,y,learning_rate,epochs):\n",
    "\n",
    "        losses = []\n",
    "        for i in range(epochs):  \n",
    "                                                    \n",
    "            preds = self.forward(X)                 # For every epoch, a forward pass followed by back propogation is done,\n",
    "                                                    # loss is calculated and weights are updated after every epoch. \n",
    "            l = self.loss(y,preds)                  # Training time can be decreased using mini-Batch gradient descent.\n",
    "            losses.append(l)\n",
    "            \n",
    "            self.backward(X,y,learning_rate)\n",
    "\n",
    "        \n",
    "        return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN = NeuralNetwork(784,22,15,10)\n",
    "losses = NN.train(X,y_oht,0.00001,1100)  # learning rate=0.00001 to avoid oershooting of the global minima\n",
    "\n",
    "#  Caution !! -> Takes about 1 minute to train on the examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)       # Losses Minimised\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = NN.predict(X_test)\n",
    "\n",
    "score = 0\n",
    "\n",
    "for i in range(y_test.shape[0]) :\n",
    "    if(y_pred[i]==np.argmax(y_test[i],axis=0)):\n",
    "        score += 1\n",
    "        \n",
    "accuracy = score/y_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.622"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy    # 62% accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 62% Accurate on testing data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
