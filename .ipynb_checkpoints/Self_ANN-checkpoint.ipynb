{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset (MNIST Flattened CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = pd.read_csv(\"mnist.csv\")\n",
    "\n",
    "# Flattened MNIST Images.\n",
    "\n",
    "data = np.array(mnist)\n",
    "\n",
    "X = data[:,:-1]\n",
    "\n",
    "y = data[:,-1]\n",
    "y_oht = to_categorical(y,num_classes=10, dtype='int32')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_oht, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective:\n",
    "        \n",
    "        We need to classify the given flattened grayscale images into the 10 digits of Decimal system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(a):\n",
    "    ea = np.exp(a)\n",
    "    return ea/np.sum(ea,axis=1,keepdims=True)\n",
    "\n",
    "# Dimensionality needs to be maintained.\n",
    "\n",
    "\n",
    "class NeuralNetwork:\n",
    "    \n",
    "    # Constructing 3 layer acrchitecture with softmax as output activation.\n",
    "    \n",
    "    def __init__(self,input_size,h1,h2,output_size):    # h1 -> number of neurons in first layer\n",
    "                                                        # h2 -> number of neurons in second layer\n",
    "        model = {}\n",
    "        model[\"W1\"] = np.random.randn(input_size,h1)    # Weight Matrix for first layer\n",
    "        model[\"b1\"] = np.zeros((1,h1))                  # Bias for first layer\n",
    "\n",
    "        model[\"W2\"] = np.random.randn(h1,h2)              # Weight Matrix for second layer\n",
    "        model[\"b2\"] = np.zeros((1,h2))                    # Bias for second layer\n",
    "\n",
    "        model[\"W3\"] = np.random.randn(h2,output_size)     # Weight Matrix for third layer \n",
    "        model[\"b3\"] = np.zeros((1,output_size))           # Bias for third layer\n",
    "        \n",
    "        self.activation_outputs = (-1,-1,-1)            # Activation outputs after each layer\n",
    "\n",
    "        self.model = model\n",
    "\n",
    "        \n",
    "        \n",
    "#   Forward Propogation ...        \n",
    "        \n",
    "    def forward(self,X):\n",
    "        \n",
    "        model = self.model\n",
    "        W1,W2,W3 = model[\"W1\"],model[\"W2\"],model[\"W3\"]\n",
    "        b1,b2,b3 = model[\"b1\"],model[\"b2\"],model[\"b3\"]\n",
    "\n",
    "        # First Layer\n",
    "        z1 = np.dot(X,W1) + b1\n",
    "        a1 = np.tanh(z1)          # tanh activation\n",
    "\n",
    "        #Second Layer\n",
    "        z2 = np.dot(a1,W2) + b2\n",
    "        a2 = np.tanh(z2)          # tanh activation\n",
    "\n",
    "        #Third Layer\n",
    "        z3 = np.dot(a2,W3) + b3\n",
    "        a3 = softmax(z3)          # Softmax Activation\n",
    "\n",
    "\n",
    "        self.activation_outputs = (a1,a2,a3)\n",
    "        return a3                 # Final Output is from softmax activation\n",
    "    \n",
    "    \n",
    "    \n",
    "#   Back Propogation...\n",
    "    \n",
    "    def backward(self,X,y,learning_rate):\n",
    "\n",
    "        m = X.shape[0]\n",
    "        model = self.model\n",
    "        (a1,a2,a3) = self.activation_outputs \n",
    "        W1,W2,W3 = model[\"W1\"],model[\"W2\"],model[\"W3\"]\n",
    "        b1,b2,b3 = model[\"b1\"],model[\"b2\"],model[\"b3\"]\n",
    "        \n",
    "        # Delta3,dw3,db3\n",
    "        delta3 = a3 - y               # for cross entropy, softmax activation\n",
    "        dw3 = np.dot(a2.T,delta3)     # (h2Xm,mXc) = (h2Xc) = W3.shape\n",
    "        db3 = np.sum(delta3,axis=0)   \n",
    "\n",
    "        # Delta2, dw2, db2\n",
    "        delta2 = np.dot(delta3,W3.T)*(1-np.square(a2))\n",
    "        dw2 = np.dot(a1.T,delta2) # (h1Xm,mXh2) = (h1Xh2) = W2.shape\n",
    "        db2 = np.sum(delta2,axis=0)\n",
    "\n",
    "        # Delta1, dw1, db1\n",
    "        delta1 = np.dot(delta2,W2.T)*(1-np.square(a1))\n",
    "        dw1 = np.dot(X.T,delta1)\n",
    "        db1 = np.sum(delta1,axis=0)\n",
    "\n",
    "        #Gradient Descent\n",
    "        \n",
    "        self.model[\"W1\"] -= learning_rate*dw1\n",
    "        self.model[\"W2\"] -= learning_rate*dw2\n",
    "        self.model[\"W3\"] -= learning_rate*dw3\n",
    "\n",
    "        self.model[\"b1\"] -= learning_rate*db1\n",
    "        self.model[\"b2\"] -= learning_rate*db2\n",
    "        self.model[\"b3\"] -= learning_rate*db3\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    def predict(self,X):\n",
    "        \n",
    "        y_pred = self.forward(X)           # Prediction is just the forward pass for X_test\n",
    "        return np.argmax(y_pred,axis=1)    # Prediction for the output with max probability \n",
    "\n",
    "\n",
    "    def loss(self,y_oht,pred):              \n",
    "        return -1*np.mean(y_oht*np.log(pred))   # Implementing Cross-Entropy Loss\n",
    "    \n",
    "    \n",
    "    \n",
    "    def train(self,X,y,learning_rate,epochs):\n",
    "\n",
    "        losses = []\n",
    "        for i in range(epochs):  \n",
    "                                                    \n",
    "            preds = self.forward(X)                 # For every epoch, a forward pass followed by back propogation is done,\n",
    "                                                    # loss is calculated and weights are updated after every epoch. \n",
    "            l = self.loss(y,preds)                  # Training time can be decreased using mini-Batch gradient descent.\n",
    "            losses.append(l)\n",
    "            \n",
    "            self.backward(X,y,learning_rate)\n",
    "\n",
    "        \n",
    "        return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN = NeuralNetwork(784,5,11,10)\n",
    "losses = NN.train(X,y_oht,0.0001,800)  # learning rate=0.00001 to avoid oershooting of the global minima\n",
    "\n",
    "#  Caution !! -> Takes about 1 minute to train on the examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)       # Losses Minimised\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction and Accuracy Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.74      0.81       247\n",
      "           1       0.96      0.91      0.94       231\n",
      "           2       0.64      0.68      0.66       181\n",
      "           3       0.80      0.56      0.66       286\n",
      "           4       0.72      0.73      0.72       202\n",
      "           5       0.48      0.47      0.48       201\n",
      "           6       0.77      0.90      0.83       159\n",
      "           7       0.83      0.79      0.81       203\n",
      "           8       0.09      0.33      0.14        52\n",
      "           9       0.76      0.68      0.72       238\n",
      "\n",
      "   micro avg       0.70      0.70      0.70      2000\n",
      "   macro avg       0.69      0.68      0.68      2000\n",
      "weighted avg       0.75      0.70      0.72      2000\n",
      " samples avg       0.70      0.70      0.70      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = NN.predict(X_test)\n",
    "\n",
    "score = 0\n",
    "\n",
    "y_pred = to_categorical(y_pred)\n",
    "\n",
    "# for i in range(y_test.shape[0]) :\n",
    "#     if(y_pred[i]==np.argmax(y_test[i],axis=0)):\n",
    "#         score += 1\n",
    "        \n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_pred,y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete !!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
